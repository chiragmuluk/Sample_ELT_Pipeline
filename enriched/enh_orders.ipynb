{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cce43f9-1e3d-4b99-9600-b82c7101a55f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary functions and types for Spark DataFrame transformations\n",
    "from pyspark.sql.functions import col, when, lit, current_timestamp, trim, sha2, concat_ws, row_number, to_date\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecabdb2d-bdc2-4955-abcd-35e94b91c8fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utils/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de6dd3aa-8796-439f-a75b-1bd404bd6947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define table names for each layer in the pipeline\n",
    "bronze_table_name = \"{}.{}\".format(raw_uk_schema,raw_orders_table)           # Raw order data (Bronze layer)\n",
    "silver_table_name = \"{}.{}\".format(enriched_uk_schema,cleaned_orders_table)  # Cleaned and enriched order data (Silver layer)\n",
    "quarantine_table_name = \"{}.{}\".format(data_quality_uk_schema,data_quality_order_table)     # Invalid or quarantined order records\n",
    "\n",
    "# Reference table names for validation\n",
    "customer_table_name = \"{}.{}\".format(enriched_uk_schema,cleaned_customers_table)  # Reference customers table\n",
    "product_table_name = \"{}.{}\".format(enriched_uk_schema,cleaned_products_table) # Reference products table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "310d67fd-f1b1-4e24-9c6f-0d7fc026c362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load today's orders from the Bronze table (filter by created_at date equals today's date)\n",
    "orders_bronze_df = spark.table(bronze_table_name).filter(col(\"created_at\").cast(\"date\") == current_timestamp().cast(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c09bcfe-b0e4-495a-9c58-04e50be74738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define a window specification to partition by order_id and order by created_at descending\n",
    "window_spec = Window.partitionBy(\"order_id\").orderBy(col(\"created_at\").desc())\n",
    "\n",
    "# Add a row number to the DataFrame to identify the latest record per order_id\n",
    "deduped_df = orders_bronze_df.withColumn(\"row_num\", row_number().over(window_spec))\n",
    "\n",
    "# Filter to keep only the latest record for each order_id (row_num == 1)\n",
    "orders_bronze_df = deduped_df.filter(\"row_num == 1\").drop(\"row_num\")\n",
    "\n",
    "# Drop unnecessary columns after deduplication\n",
    "orders_bronze_df = orders_bronze_df.drop(\"system_of_record\", \"created_at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b6fc167-31c8-4c46-904e-e01b2876b498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform and standardize columns for Silver layer\n",
    "orders_silver_df = (\n",
    "    orders_bronze_df\n",
    "    # Ensure total_amount is DoubleType\n",
    "    .withColumn(\"total_amount\", col(\"total_amount\").cast(DoubleType()))\n",
    "    # Parse order_date to DateType\n",
    "    .withColumn(\"order_date\", to_date(col(\"order_date\"), \"yyyy-MM-dd\"))\n",
    "    # Ensure quantity is IntegerType\n",
    "    .withColumn(\"quantity\", col(\"quantity\").cast(IntegerType()))\n",
    "    # Add processing timestamp\n",
    "    .withColumn(\"_processing_timestamp\", current_timestamp())\n",
    "    # Rename file_path for lineage tracking\n",
    "    .withColumnRenamed(\"file_path\", \"_source_file_path\")\n",
    "    # Initialize error message column\n",
    "    .withColumn(\"_error_message\", lit(None).cast(\"string\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "522e1fb7-e5f2-4ec6-857c-2b728bf6131b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define validation rules as tuples for clarity.\n",
    "# Each tuple contains a condition and the corresponding error message.\n",
    "validation_rules = [\n",
    "    (col(\"order_id\").isNull() | (trim(col(\"order_id\")) == \"\"), \"Order ID is missing or blank.\"),\n",
    "    (col(\"customer_id\").isNull() | (trim(col(\"customer_id\")) == \"\"), \"Customer ID is missing or blank.\"),\n",
    "    (col(\"product_id\").isNull() | (trim(col(\"product_id\")) == \"\"), \"Product ID is missing or blank.\"),\n",
    "    (col(\"order_date\").isNull(), \"Order date is missing.\"),\n",
    "    (col(\"total_amount\").isNull() | (col(\"total_amount\") <= 0), \"Total amount is missing or not positive.\"),\n",
    "    (col(\"quantity\").isNull() | (col(\"quantity\") <= 0), \"Quantity is missing or not positive.\"),\n",
    "    (~col(\"status\").isin(\"Shipped\", \"Delivered\", \"Processing\"), \"Status is invalid.\")\n",
    "]\n",
    "\n",
    "# Chain validation conditions using when/otherwise to build a single error message column.\n",
    "error_message_chain = lit(None)\n",
    "for condition, error in reversed(validation_rules):\n",
    "    error_message_chain = when(condition, error).otherwise(error_message_chain)\n",
    "\n",
    "# Apply the chained validation logic to the DataFrame.\n",
    "orders_silver_df = orders_silver_df.withColumn(\n",
    "    \"_error_message\",\n",
    "    error_message_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "601d8904-26fd-4276-8026-ef73ce275e3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load reference DataFrames and rename columns for join clarity\n",
    "customers_df = (\n",
    "    spark.table(customer_table_name)\n",
    "    .select(col(\"customer_id\").alias(\"ref_customer_id\"))  # Rename for join clarity\n",
    ")\n",
    "products_df = (\n",
    "    spark.table(product_table_name)\n",
    "    .select(col(\"product_id\").alias(\"ref_product_id\"))  # Rename for join clarity\n",
    ")\n",
    "\n",
    "# Join orders_silver_df with reference tables to check referential integrity\n",
    "orders_silver_df = (\n",
    "    orders_silver_df\n",
    "    # Left join with customers reference table\n",
    "    .join(customers_df, trim(col(\"customer_id\")) == customers_df.ref_customer_id, \"left\")\n",
    "    # Left join with products reference table\n",
    "    .join(products_df, trim(col(\"product_id\")) == products_df.ref_product_id, \"left\")\n",
    "    # Update _error_message column based on referential integrity checks\n",
    "    .withColumn(\n",
    "        \"_error_message\",\n",
    "        when(col(\"_error_message\").isNotNull(), col(\"_error_message\"))  # Preserve existing error if present\n",
    "        .when(customers_df.ref_customer_id.isNull(), \"Customer ID does not exist in reference table.\")  # Customer not found\n",
    "        .when(products_df.ref_product_id.isNull(), \"Product ID does not exist in reference table.\")  # Product not found\n",
    "        .otherwise(lit(None))  # No error\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop reference columns after join\n",
    "orders_silver_df = orders_silver_df.drop(\"ref_customer_id\", \"ref_product_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b59721a-f0d4-46e6-86de-e47c0684aa3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter valid records (no error message) and drop the _error_message column\n",
    "valid_records_df = orders_silver_df.filter(col(\"_error_message\").isNull()).drop(\"_error_message\")\n",
    "\n",
    "# Filter invalid records (with error message) for quarantine\n",
    "invalid_records_df = orders_silver_df.filter(col(\"_error_message\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbf5250c-264a-420b-b611-07e6173862bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load reference DataFrames and rename columns for join clarity\n",
    "customers_df = (\n",
    "    spark.table(customer_table_name)\n",
    "    .select(col(\"customer_id\").alias(\"ref_customer_id\"))  # Rename for join clarity\n",
    ")\n",
    "products_df = (\n",
    "    spark.table(product_table_name)\n",
    "    .select(col(\"product_id\").alias(\"ref_product_id\"))  # Rename for join clarity\n",
    ")\n",
    "\n",
    "# Join orders_silver_df with reference tables to check referential integrity\n",
    "orders_silver_df = (\n",
    "    orders_silver_df\n",
    "    # Left join with customers reference table\n",
    "    .join(customers_df, trim(col(\"customer_id\")) == customers_df.ref_customer_id, \"left\")\n",
    "    # Left join with products reference table\n",
    "    .join(products_df, trim(col(\"product_id\")) == products_df.ref_product_id, \"left\")\n",
    "    # Update _error_message column based on referential integrity checks\n",
    "    .withColumn(\n",
    "        \"_error_message\",\n",
    "        when(col(\"_error_message\").isNotNull(), col(\"_error_message\"))  # Preserve existing error if present\n",
    "        .when(customers_df.ref_customer_id.isNull(), \"Customer ID does not exist in reference table.\")  # Customer not found\n",
    "        .when(products_df.ref_product_id.isNull(), \"Product ID does not exist in reference table.\")  # Product not found\n",
    "        .otherwise(lit(None))  # No error\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop reference columns after join\n",
    "orders_silver_df = orders_silver_df.drop(\"ref_customer_id\", \"ref_product_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1475caca-c15e-4a23-9501-1fd0aa925eb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate a unique hash key for each order based on order_id, customer_id, product_id, and order_date\n",
    "valid_records_df = valid_records_df.withColumn(\"order_hash_key\",\n",
    "    sha2(\n",
    "        concat_ws(\n",
    "            \"^\",\n",
    "            col(\"order_id\"),\n",
    "            col(\"customer_id\"),\n",
    "            col(\"product_id\"),\n",
    "            col(\"order_date\")\n",
    "        ),\n",
    "        256\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate a hash key for the row based on total_amount, status, and quantity for change tracking\n",
    "valid_records_df = valid_records_df.withColumn(\"row_hash_key\",\n",
    "    sha2(\n",
    "        concat_ws(\n",
    "            \"^\",\n",
    "            col(\"total_amount\"),\n",
    "            col(\"status\"),\n",
    "            col(\"quantity\")\n",
    "        ),\n",
    "        256\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589946f2-2e5c-48f2-a66c-41aebbb8334e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write valid records to the Silver layer Delta table\n",
    "valid_records_df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .saveAsTable(silver_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e5e0ad-e8ea-4308-a419-715f07b7241f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write invalid records to the Quarantine Delta table\n",
    "invalid_records_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(quarantine_table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5130952999235148,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "enh_orders",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
